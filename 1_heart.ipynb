{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a557939d","cell_type":"markdown","source":"## ‚öôÔ∏è **Heart Disease Prediction using Logistic Regression and KNN**\nA complete end-to-end ML pipeline built for Google Colab.\n\nThis notebook demonstrates data exploration, visualization, model building, and evaluation for predicting heart disease.","metadata":{}},{"id":"20818973","cell_type":"code","source":"\n# ‚úÖ Install Required Libraries\n!pip install pandas matplotlib seaborn scikit-learn\n\n# ‚úÖ Import essential libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statistics as s\n\n# ‚úÖ Visualization style setup\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")\n\nprint(\"‚úÖ Libraries successfully imported!\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"1cb862bc","cell_type":"code","source":"\n# ‚úÖ Load Dataset\ndf = pd.read_csv(\"https://raw.githubusercontent.com/krishnaik06/Herat-Disease-UCI-Dataset/master/heart.csv\")\ndf.head()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"173869ba","cell_type":"code","source":"\n# ‚úÖ Dataset Information\ndf.info()\nprint(\"Shape:\", df.shape)\nprint(\"Size:\", df.size)\ndf.describe()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"a60ab468","cell_type":"code","source":"\n# ‚úÖ Data Type and Missing Value Check\nprint(\"Data Types:\n\", df.dtypes.value_counts())\nprint(\"\\nMissing Values per Column:\\n\", df.isnull().sum())\nprint(\"\\nPercentage of Missing Values:\\n\", (df.isnull().sum()/len(df))*100)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"f2cfaf23","cell_type":"code","source":"\n# ‚úÖ Correlation Heatmap\ncorr_matrix = df.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"2a3689b8","cell_type":"code","source":"\n# ‚úÖ Average Age Calculation\naverage_age = s.mean(df['age'])\nprint(f\"Average Age of Patients: {average_age:.2f} years\")\ndf[['age', 'sex', 'trestbps', 'chol']].head()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"b153dae8","cell_type":"code","source":"\n# ‚úÖ Split Dataset\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop('target', axis=1)\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=56)\n\nprint(\"Training Data Shape:\", X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"32288eaa","cell_type":"code","source":"\n# ‚úÖ Evaluation Function\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        print(\"\\nüìò Train Performance:\")\n    else:\n        pred = clf.predict(X_test)\n        print(\"\\nüìï Test Performance:\")\n    \n    acc = accuracy_score(y_test if not train else y_train, pred)*100\n    print(f\"Accuracy: {acc:.2f}%\")\n    print(\"Classification Report:\\n\", classification_report(y_test if not train else y_train, pred))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test if not train else y_train, pred))\n","metadata":{},"outputs":[],"execution_count":null},{"id":"03924f9b","cell_type":"code","source":"\n# ‚úÖ Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\n\nlr_clf = LogisticRegression(solver='liblinear')\nlr_clf.fit(X_train, y_train)\n\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=False)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"26e2fed6","cell_type":"code","source":"\n# ‚úÖ K-Nearest Neighbors Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier(n_neighbors=5)\nknn_clf.fit(X_train, y_train)\n\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=False)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"a5e890f4","cell_type":"code","source":"\n# ‚úÖ Model Comparison\nlr_train_acc = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\nlr_test_acc = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n\nknn_train_acc = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\nknn_test_acc = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n\nresults_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'K-Nearest Neighbors'],\n    'Training Accuracy %': [lr_train_acc, knn_train_acc],\n    'Testing Accuracy %': [lr_test_acc, knn_test_acc]\n})\nresults_df\n","metadata":{},"outputs":[],"execution_count":null},{"id":"568a568a","cell_type":"code","source":"\n# ‚úÖ Visualization of Model Comparison\nplt.figure(figsize=(8, 5))\nsns.barplot(data=results_df, x='Model', y='Testing Accuracy %')\nplt.title(\"Model Performance Comparison (Testing Accuracy)\")\nplt.ylabel(\"Accuracy %\")\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null}]}